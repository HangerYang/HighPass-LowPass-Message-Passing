{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "fc428ca26affa5af9dd5c051ba311245887c388f59b707cd674a8c125ddecc9a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn as gnn\n",
    "import torch_geometric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.linalg\n",
    "from torch_geometric.nn import GATConv\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.datasets import Planetoid\n",
    "# name_data = 'Cora'\n",
    "# dataset = Planetoid(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WebKB\n",
    "# name_data = 'Wisconsin'\n",
    "# dataset = WebKB(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "# name_data = 'CiteSeer'\n",
    "# dataset = Planetoid(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WebKB\n",
    "# name_data = 'Cornell'\n",
    "# dataset = WebKB(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WebKB\n",
    "# name_data = 'Texas'\n",
    "# dataset = WebKB(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WikipediaNetwork\n",
    "# name_data = 'Chameleon'\n",
    "# dataset = WikipediaNetwork(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "from torch_geometric.datasets import WikipediaNetwork\n",
    "name_data = 'Squirrel'\n",
    "dataset = WikipediaNetwork(root= '/tmp/' + name_data, name = name_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "\n",
    "edges = data.edge_index\n",
    "\n",
    "#dimension: num_nodes * num_features\n",
    "features = data.x\n",
    "\n",
    "num_nodes = features.shape[0]\n",
    "num_features = features.shape[1]\n",
    "#dimension: num_nodes * num_nodes\n",
    "adj = torch.zeros((num_nodes,num_nodes))\n",
    "degree = torch.zeros((num_nodes,num_nodes))\n",
    "for i in range(edges.shape[1]):\n",
    "    first = edges[0][i]\n",
    "    second = edges[1][i]\n",
    "    adj[first][second] = 1\n",
    "    adj[second][first] = 1\n",
    "for i in range(num_nodes):\n",
    "    degree[i][i] = sum(adj[i][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sample(num_nodes):\n",
    "  sample_num = int(num_nodes*0.6)\n",
    "  sample_lst = np.random.choice(num_nodes,sample_num, replace = False)\n",
    "  train_mask = [False] * num_nodes\n",
    "  test_mask = [True] * num_nodes\n",
    "  for i in sample_lst:\n",
    "    train_mask[i] = True\n",
    "    test_mask[i] = False\n",
    "  train_mask = torch.tensor(train_mask)\n",
    "  test_mask = torch.tensor(test_mask)\n",
    "  return train_mask, test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_parameter(model):\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = degree.to(device)\n",
    "adj = adj.to(device)\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBLayer(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "      super().__init__()\n",
    "      self.low = nn.Linear(dim_in, dim_out, bias = False)\n",
    "      gain = nn.init.calculate_gain(\"relu\")\n",
    "      nn.init.xavier_normal_(self.low.weight, gain)\n",
    "      self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input, adj, degree):\n",
    "      lap = degree - adj\n",
    "      inter = scipy.linalg.fractional_matrix_power(degree.cpu(), (-1/2))\n",
    "      d_inv = torch.from_numpy(inter).to(device)\n",
    "      Llp = torch.mm(torch.mm(d_inv, lap), d_inv)\n",
    "      Hl = torch.mm(Llp, self.activation(self.low(input)))\n",
    "      return Hl\n",
    "\n",
    "    def reset_parameter():\n",
    "      gain = nn.init.calculate_gain(\"relu\")\n",
    "      nn.init.xavier_normal_(self.low.weight, gain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_head, nhid):\n",
    "        super().__init__()\n",
    "        self.gc1 = GATConv(dataset.num_node_features, nhid, heads=num_head)\n",
    "        self.gc2 = GATConv(nhid*num_head, dataset.num_classes)\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.gc1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.gc2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBGAT(torch.nn.Module):\n",
    "    def __init__(self, num_head, nhid):\n",
    "      super().__init__()\n",
    "      self.fb1 = FBLayer(dataset.num_node_features, nhid*num_head)\n",
    "      self.fb2 = FBLayer(nhid*num_head ,dataset.num_classes)\n",
    "      self.conv1 = GATConv(dataset.num_node_features, nhid, heads = num_head)\n",
    "      self.conv2 = GATConv(nhid*num_head, dataset.num_classes)\n",
    "      self.aL_1 = torch.nn.Parameter(torch.rand(1))\n",
    "      self.aH_1 = torch.nn.Parameter(torch.rand(1))\n",
    "      self.aL_2 = torch.nn.Parameter(torch.rand(1))\n",
    "      self.aH_2 = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, data, adj, degree):\n",
    "      input, edge_index = data.x, data.edge_index\n",
    "      x_1 = self.fb1(input, adj, degree) #high pass\n",
    "      y_1 = self.conv1(input, edge_index) #low pass layer\n",
    "      z_1 = self.aL_1 * x_1 + self.aH_1 * y_1\n",
    "      z_1 = F.elu(z_1)\n",
    "      z_1 = F.dropout(z_1, training=self.training)\n",
    "      x_2 = self.fb2(z_1, adj, degree)\n",
    "      y_2 = self.conv2(z_1, edge_index)\n",
    "      z_2 = self.aL_2 * x_2 + self.aH_2 * y_2\n",
    "\n",
    "      return F.log_softmax(z_2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Trial: 0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 326.00 MiB (GPU 0; 2.00 GiB total capacity; 1.06 GiB already allocated; 65.44 MiB free; 1.09 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a55008562d5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0moptimizer_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmodel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 326.00 MiB (GPU 0; 2.00 GiB total capacity; 1.06 GiB already allocated; 65.44 MiB free; 1.09 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "acc_list_2 = []\n",
    "for i in range(5):\n",
    "    model_2 = GAT(48, 8).to(device)\n",
    "    optimizer_2 = torch.optim.Adam(model_2.parameters(), lr=0.05, weight_decay=5e-5)\n",
    "    model_2.train()\n",
    "    print(\"Number of Trial: \" + str(i))\n",
    "    reset_parameter(model_2)\n",
    "    train_mask, test_mask = data_sample(num_nodes)\n",
    "    for epoch in range(100):\n",
    "        optimizer_2.zero_grad()\n",
    "        out = model_2(data)\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask]) \n",
    "        loss.backward()\n",
    "        optimizer_2.step()\n",
    "    model_2.eval()\n",
    "    _, pred = model_2(data).max(dim=1)\n",
    "    correct = int(pred[test_mask].eq(data.y[test_mask]).sum().item())\n",
    "    acc = correct / int(test_mask.sum())\n",
    "    acc_list_2.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nan\n",
      "C:\\Users\\Hanger\\Anaconda3\\envs\\torch\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\Hanger\\Anaconda3\\envs\\torch\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(acc_list_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Trial: 0\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "Number of Trial: 1\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "for i in range(5):\n",
    "    model = FBGAT(48, 8).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=5e-5)\n",
    "    model.train()\n",
    "    print(\"Number of Trial: \" + str(i))\n",
    "    reset_parameter(model)\n",
    "    train_mask, test_mask = data_sample(num_nodes)\n",
    "    for epoch in range(100):\n",
    "        if epoch % 20 == 0:\n",
    "            print(epoch)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data, adj, degree)\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask]) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    _, pred = model(data, adj, degree).max(dim=1)\n",
    "    correct = int(pred[test_mask].eq(data.y[test_mask]).sum() .item())\n",
    "    acc = correct / int(test_mask.sum())\n",
    "    acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FBGAT Accuracy: 0.8579\n"
     ]
    }
   ],
   "source": [
    "print('FBGAT Accuracy: {:.4f}'.format(np.mean(acc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "aL_1 tensor([0.2276], device='cuda:0')\n",
      "aH_1 tensor([0.0994], device='cuda:0')\n",
      "aL_2 tensor([0.4996], device='cuda:0')\n",
      "aH_2 tensor([0.3774], device='cuda:0')\n",
      "fb1.low.weight tensor([[-2.0678e-01,  1.8474e-02,  5.6937e-03,  ...,  2.4587e-01,\n",
      "          7.2109e-02, -1.6569e-01],\n",
      "        [-1.3639e-03, -6.6650e-05,  4.0031e-05,  ...,  1.0259e-03,\n",
      "          2.8664e-03, -1.0082e-03],\n",
      "        [-9.0461e-02, -1.8909e-02,  4.0823e-02,  ...,  2.2229e-02,\n",
      "         -2.6266e-01, -2.0773e-01],\n",
      "        ...,\n",
      "        [ 2.1201e-01,  2.5107e-02, -4.7889e-02,  ..., -1.5644e-01,\n",
      "          5.5418e-02, -9.4412e-02],\n",
      "        [-1.0996e-01,  2.2267e-03,  3.1053e-04,  ...,  1.3089e-01,\n",
      "          3.8182e-02, -6.5425e-02],\n",
      "        [-2.1739e-03,  7.7339e-05, -2.1302e-03,  ..., -9.4681e-04,\n",
      "         -2.0912e-02, -6.9897e-04]], device='cuda:0')\n",
      "fb2.low.weight tensor([[-0.3223,  0.5569, -0.4501,  ..., -0.1506, -0.1959, -0.3345],\n",
      "        [ 0.1219,  0.2431,  0.0175,  ..., -0.2430,  0.3025, -0.3304],\n",
      "        [ 0.2844,  0.2167, -0.5551,  ..., -0.2639, -0.6571, -0.2899],\n",
      "        [ 0.0514, -0.1125, -0.6068,  ...,  0.3847, -0.7865, -0.5811],\n",
      "        [ 0.3938, -0.0792, -0.1094,  ...,  0.5012,  0.1028, -0.3643]],\n",
      "       device='cuda:0')\n",
      "conv1.att_l tensor([[[ 2.5411e-01,  2.7136e-01,  4.7508e-01,  3.5694e-01, -8.7537e-02,\n",
      "           9.6685e-02,  3.1395e-01,  5.9068e-01],\n",
      "         [-8.7817e-01, -3.6827e-01,  2.5904e-01, -4.2376e-01, -3.3610e-01,\n",
      "          -1.4698e-01, -2.5772e-01,  4.9810e-02],\n",
      "         [ 3.8365e-01,  4.3815e-01, -2.1496e-02, -3.2911e-01,  5.4522e-01,\n",
      "          -1.0927e-01,  3.0693e-02,  4.3092e-01],\n",
      "         [-2.1357e-01,  4.6298e-01, -9.9391e-01, -3.4014e-01, -2.9490e-01,\n",
      "           2.5367e-01,  2.6484e-01,  1.4651e-01],\n",
      "         [-5.1466e-01,  7.0349e-02, -1.6234e-01, -9.7541e-02,  4.9431e-01,\n",
      "           1.0151e-01, -1.6607e-01, -3.9659e-01],\n",
      "         [ 6.6764e-02,  1.4758e-01,  2.0067e-02,  5.9522e-01,  4.4817e-01,\n",
      "          -4.5768e-01, -2.7161e-03, -3.8943e-02],\n",
      "         [-2.4214e-01, -1.5686e-01, -3.8991e-01,  1.5503e-01,  3.1327e-03,\n",
      "           8.6478e-02,  5.8093e-01,  2.2198e-01],\n",
      "         [-6.0783e-01, -1.1490e-02, -4.2720e-01,  4.6976e-01, -5.5550e-02,\n",
      "           3.5625e-01, -4.1799e-01, -2.2793e-01],\n",
      "         [-2.2784e-01, -5.9674e-01,  1.5098e-01,  1.6853e-01,  1.9320e-01,\n",
      "           4.3658e-01, -1.2016e-01,  3.8359e-01],\n",
      "         [ 3.2955e-01, -2.0476e-01,  2.5001e-01,  7.6405e-02,  4.7172e-01,\n",
      "          -1.9875e-01, -2.3108e-01,  3.3621e-01],\n",
      "         [ 8.7135e-02,  6.6885e-02,  5.3314e-01,  1.7941e-01, -7.4193e-01,\n",
      "           3.1947e-01,  1.6113e-01,  1.5663e-01],\n",
      "         [-2.5239e-01,  6.4001e-02, -5.8675e-01, -5.8605e-01, -5.3117e-01,\n",
      "          -5.2323e-01,  1.2483e-02,  2.5199e-01],\n",
      "         [-8.9125e-02, -1.9498e-01, -4.2086e-01,  1.0673e-01, -3.5635e-01,\n",
      "           3.4437e-01,  5.4659e-01,  2.2402e-01],\n",
      "         [ 6.3316e-01,  4.7404e-01, -7.7698e-02,  2.0659e-02, -2.4393e-01,\n",
      "           7.1687e-01,  1.5724e-01, -6.3673e-01],\n",
      "         [-2.6352e-01, -5.0162e-01, -6.8981e-02,  1.9609e-01,  4.3687e-02,\n",
      "           2.3134e-01,  1.7310e-01, -2.2031e-01],\n",
      "         [-2.9238e-02,  5.3091e-01, -1.8091e-01, -3.7953e-01, -2.9575e-01,\n",
      "           3.8591e-01,  2.8567e-01,  3.1551e-01],\n",
      "         [-3.2460e-01, -1.5691e-01,  1.3571e-01, -4.5288e-01, -3.8100e-01,\n",
      "           6.2537e-01, -1.1490e-01, -5.6702e-01],\n",
      "         [ 1.3353e-01,  5.3624e-01,  3.6301e-01, -3.5813e-01, -9.1890e-02,\n",
      "          -6.0590e-01,  1.2763e-01, -1.3605e-01],\n",
      "         [ 3.7232e-01,  1.6885e-01, -6.3392e-01, -1.9506e-01, -3.0315e-01,\n",
      "          -2.3327e-01,  3.8393e-01, -4.2760e-01],\n",
      "         [-1.1168e-01, -6.2830e-01,  1.1202e-01,  6.2761e-02, -2.1394e-01,\n",
      "           2.4424e-01, -6.5033e-01,  5.3057e-01],\n",
      "         [-6.2781e-01, -5.9967e-02,  7.0234e-02,  4.1861e-01, -5.4687e-01,\n",
      "           6.0242e-01,  5.8957e-02, -1.4546e-02],\n",
      "         [ 2.5029e-01,  1.0710e-01, -4.0891e-01, -5.6229e-01, -1.4444e-01,\n",
      "          -6.7294e-02, -2.8911e-01,  3.8046e-01],\n",
      "         [ 3.4627e-01,  1.3770e-01,  3.0331e-01,  2.9172e-01,  6.9393e-02,\n",
      "           1.5215e-01,  6.4470e-01,  2.3153e-01],\n",
      "         [ 2.2287e-01,  2.2918e-01, -2.9208e-01,  1.3746e-01, -1.3563e-01,\n",
      "           6.3803e-01, -7.9623e-01, -3.2885e-01],\n",
      "         [ 3.8149e-01, -5.4492e-01,  2.8208e-01,  8.0081e-01, -3.6036e-01,\n",
      "          -2.3031e-01,  5.5781e-01,  1.2627e-01],\n",
      "         [ 4.5216e-01, -3.9414e-01,  1.7424e-01,  7.9057e-01, -1.4872e-01,\n",
      "           9.6613e-01, -3.3951e-05,  3.9677e-01],\n",
      "         [ 7.9824e-01, -3.5726e-01,  1.8571e-01,  2.0785e-01,  1.1899e-01,\n",
      "          -5.7251e-01, -2.0162e-01,  5.4898e-01],\n",
      "         [-1.0815e-01,  5.7070e-01, -1.6860e-01, -4.8137e-03,  7.8351e-02,\n",
      "           6.9715e-02, -1.9403e-01,  3.3620e-01],\n",
      "         [-2.9644e-02, -6.5872e-02,  3.1480e-01,  1.7832e-02, -7.5604e-01,\n",
      "           1.4315e-01, -5.6537e-01, -1.8621e-01],\n",
      "         [-2.4593e-01,  3.2877e-01, -6.7636e-01, -8.9992e-02, -5.1980e-01,\n",
      "          -1.2677e-01,  4.5458e-01,  1.5721e-02],\n",
      "         [ 3.0855e-01,  8.1987e-01,  4.0083e-02,  2.1342e-01,  6.6159e-03,\n",
      "          -5.9140e-01,  7.4087e-02, -2.8659e-01],\n",
      "         [-2.6872e-01,  2.3601e-01,  8.2370e-01,  2.9422e-02,  1.5861e-01,\n",
      "           1.3132e-01,  2.6154e-01, -2.2521e-02]]], device='cuda:0')\n",
      "conv1.att_r tensor([[[-0.0956,  0.4401, -0.4831, -0.3571,  0.0107, -0.1757,  0.0725,\n",
      "           0.2194],\n",
      "         [ 0.1317,  0.0612,  0.0626, -0.0228, -0.0368,  0.0185, -0.0098,\n",
      "          -0.0374],\n",
      "         [ 0.1429,  0.3769, -0.2405,  0.2002,  0.2967,  0.0349,  0.2057,\n",
      "           0.2163],\n",
      "         [-0.3616,  0.1983,  0.0398,  0.2087,  0.4264,  0.1934,  0.1333,\n",
      "           0.2786],\n",
      "         [-0.4131,  0.0469, -0.2374,  0.0047,  0.3979,  0.2427, -0.0109,\n",
      "          -0.2948],\n",
      "         [-0.2224, -0.1363, -0.1218,  0.0537,  0.0831,  0.1393,  0.2435,\n",
      "           0.1824],\n",
      "         [-0.3416,  0.0260,  0.0119, -0.3268,  0.1180, -0.3158,  0.0633,\n",
      "          -0.3418],\n",
      "         [ 0.0958, -0.2996, -0.4106,  0.0968,  0.0842,  0.2536, -0.0967,\n",
      "          -0.2067],\n",
      "         [-0.0607, -0.3944,  0.1965,  0.0331,  0.2802,  0.0348,  0.0912,\n",
      "          -0.0894],\n",
      "         [-0.4577,  0.1267,  0.4575, -0.3199,  0.0779, -0.1258, -0.0550,\n",
      "           0.2056],\n",
      "         [ 0.2217,  0.3518,  0.0742,  0.2274, -0.1851,  0.3902, -0.0823,\n",
      "           0.0840],\n",
      "         [-0.3489, -0.3740, -0.1998,  0.2343, -0.3512, -0.1558, -0.2524,\n",
      "          -0.2061],\n",
      "         [-0.7000, -0.3335,  0.8850, -0.0769,  0.3559, -0.2558, -0.3970,\n",
      "          -0.0608],\n",
      "         [ 0.2487,  0.1767, -0.0749, -0.1463, -0.2615,  0.1042,  0.1391,\n",
      "          -0.2685],\n",
      "         [ 0.1027, -0.1775, -0.3915,  0.6828,  0.2560,  0.4852,  0.0589,\n",
      "           0.6442],\n",
      "         [ 0.3062,  0.1025, -0.1016,  0.2603,  0.1700,  0.0843, -0.1683,\n",
      "          -0.0694],\n",
      "         [-0.4317,  0.1833, -0.2205,  0.1345,  0.2072,  0.2715,  0.2813,\n",
      "           0.1867],\n",
      "         [ 0.1815, -0.0262,  0.2933,  0.1638,  0.3059,  0.2413,  0.3309,\n",
      "           0.0725],\n",
      "         [ 0.1775,  0.1807, -0.4412,  0.1533,  0.3635,  0.2697, -0.2838,\n",
      "          -0.2972],\n",
      "         [ 0.2031, -0.0519,  0.0224,  0.1298, -0.1415, -0.0732,  0.1002,\n",
      "           0.1000],\n",
      "         [-0.0376, -0.0594,  0.0057,  0.2650, -0.0355,  0.3456,  0.3494,\n",
      "           0.1718],\n",
      "         [ 0.2287,  0.0358, -0.2296, -0.0449, -0.0538, -0.1955, -0.3260,\n",
      "           0.2426],\n",
      "         [-0.5755, -0.4056, -0.5289, -0.7937, -0.5841,  0.0579, -0.6382,\n",
      "           0.2867],\n",
      "         [-0.0734, -0.1757, -0.1143,  0.4635, -0.1738, -0.0823, -0.2228,\n",
      "          -0.1790],\n",
      "         [ 0.2114, -0.0347, -0.3197, -0.2502, -0.0121, -0.3565, -0.0549,\n",
      "           0.1615],\n",
      "         [-0.2069,  0.5108, -0.4840,  0.3101,  0.1129, -0.4195, -0.0346,\n",
      "          -0.4338],\n",
      "         [-0.2246,  0.0765,  0.1502,  0.2804, -0.0059,  0.0052, -0.0281,\n",
      "          -0.1478],\n",
      "         [-0.3139,  0.1412, -0.2925, -0.6230, -0.1958, -0.2541, -0.1666,\n",
      "          -0.1224],\n",
      "         [ 0.1784, -0.3439,  0.0495, -0.1790, -0.5308,  0.3343,  0.1369,\n",
      "          -0.3400],\n",
      "         [ 0.1246,  0.3201, -0.2610, -0.3115, -0.1496, -0.2599,  0.0409,\n",
      "           0.4585],\n",
      "         [-0.3949,  0.0439, -0.1373,  0.0392,  0.1067, -0.0520, -0.1851,\n",
      "          -0.1736],\n",
      "         [ 0.1204,  0.4420, -0.0592, -0.5637,  0.4101,  0.4121,  0.6202,\n",
      "           0.3671]]], device='cuda:0')\n",
      "conv1.bias tensor([-0.0944,  0.0085, -0.1583, -0.0381,  0.0055, -0.1646, -0.2032,  0.0831,\n",
      "        -0.0040,  0.0214, -0.0447,  0.0583, -0.0447,  0.0064, -0.1095, -0.3541,\n",
      "        -0.1123, -0.0779,  0.0187, -0.0953,  0.0967, -0.0272, -0.1638, -0.2248,\n",
      "        -0.0881, -0.0896, -0.2530, -0.1596, -0.1292, -0.0294, -0.0667, -0.2114,\n",
      "        -0.0195, -0.0276,  0.0392,  0.0543, -0.1325, -0.1256, -0.0378, -0.2625,\n",
      "        -0.1685, -0.0714,  0.0075, -0.0168, -0.2364,  0.1077, -0.0422, -0.1102,\n",
      "         0.0251, -0.1534, -0.0211, -0.2426, -0.1496, -0.1727,  0.1828, -0.0919,\n",
      "        -0.0048, -0.3390, -0.1250, -0.1081, -0.1458, -0.1009, -0.0981, -0.1833,\n",
      "        -0.0564,  0.1537, -0.1585, -0.2309, -0.0298, -0.0049,  0.0962, -0.0676,\n",
      "        -0.1283,  0.0277, -0.0902,  0.0202, -0.0188,  0.0480, -0.0876, -0.1099,\n",
      "        -0.0381, -0.1001, -0.1797, -0.1644,  0.1391, -0.0362,  0.0124,  0.0590,\n",
      "        -0.2938, -0.1300, -0.0408, -0.1500, -0.2610, -0.1274, -0.1337, -0.0881,\n",
      "         0.1053, -0.0907,  0.0439, -0.2845, -0.0825, -0.0403, -0.0891,  0.2710,\n",
      "        -0.1339, -0.0076, -0.1362, -0.0734, -0.1690, -0.0752, -0.0274, -0.1676,\n",
      "         0.0305, -0.0620,  0.0260, -0.1984,  0.0564,  0.0216, -0.2640,  0.0803,\n",
      "        -0.0463,  0.1227,  0.1246,  0.0477,  0.1069,  0.0055, -0.2015, -0.1295,\n",
      "         0.1914, -0.1702,  0.0109, -0.0889,  0.1283, -0.1393,  0.0979, -0.1173,\n",
      "        -0.0436, -0.1153,  0.0218, -0.2307, -0.0092, -0.0805, -0.0593, -0.2598,\n",
      "         0.0984, -0.1677,  0.0782,  0.0005, -0.0163,  0.0483,  0.0755, -0.0962,\n",
      "        -0.1874, -0.2138, -0.1566, -0.1179, -0.0853, -0.0069,  0.0498, -0.0106,\n",
      "        -0.1550,  0.1933,  0.0962, -0.1574, -0.0724, -0.0366, -0.2803, -0.0627,\n",
      "         0.0625,  0.0217,  0.0149, -0.1332, -0.2047, -0.1783,  0.0269,  0.0250,\n",
      "        -0.3140, -0.0596, -0.0019, -0.1349, -0.0487,  0.0788,  0.0012, -0.0312,\n",
      "        -0.0161,  0.0373, -0.0305, -0.0799, -0.1673, -0.1559,  0.0521,  0.0108,\n",
      "        -0.0313,  0.3392, -0.1822,  0.0977,  0.0381, -0.0166, -0.1398, -0.1334,\n",
      "        -0.2781, -0.0749, -0.1847,  0.1350, -0.0352, -0.0082,  0.0786,  0.0103,\n",
      "         0.0260, -0.2019, -0.0818,  0.0147,  0.0610, -0.0392, -0.0921,  0.1306,\n",
      "         0.1167, -0.0774, -0.0683,  0.1338, -0.1386, -0.0672,  0.0204, -0.0687,\n",
      "         0.0789, -0.0273, -0.0018, -0.1207, -0.0346,  0.1567,  0.0867, -0.1598,\n",
      "        -0.0224, -0.0391, -0.0414, -0.0014, -0.0718,  0.0868,  0.1728, -0.0362,\n",
      "        -0.0004,  0.1234, -0.0259,  0.0768, -0.1099, -0.1159, -0.1849,  0.2124,\n",
      "        -0.0510,  0.0280,  0.1032,  0.2339, -0.0835, -0.0771, -0.1855, -0.0261],\n",
      "       device='cuda:0')\n",
      "conv1.lin_l.weight tensor([[-4.9373e-02,  1.4608e-03,  1.1880e-02,  ..., -8.2750e-03,\n",
      "         -1.0866e-01,  1.6931e-04],\n",
      "        [-1.1582e-01, -7.7011e-03,  8.5262e-05,  ..., -1.0006e-01,\n",
      "          5.5109e-02, -1.2046e-02],\n",
      "        [-1.7558e-01,  1.9173e-03, -6.7877e-03,  ..., -1.2251e-01,\n",
      "         -1.3565e-01, -8.4301e-03],\n",
      "        ...,\n",
      "        [ 5.6540e-02, -4.6321e-02, -2.8121e-02,  ..., -6.5364e-03,\n",
      "         -8.9692e-02, -7.6695e-02],\n",
      "        [-2.3009e-01,  9.0778e-03,  2.7515e-02,  ..., -3.1124e-02,\n",
      "         -2.4793e-01, -2.8266e-02],\n",
      "        [-9.2426e-03,  1.2372e-02,  9.3488e-03,  ..., -3.9041e-02,\n",
      "         -2.0812e-01,  1.1158e-02]], device='cuda:0')\n",
      "conv2.att_l tensor([[[ 0.0641, -0.2149, -0.6840,  0.0699, -0.3535]]], device='cuda:0')\n",
      "conv2.att_r tensor([[[-0.2832, -1.0247, -0.0430,  0.5766, -0.7721]]], device='cuda:0')\n",
      "conv2.bias tensor([-0.3136,  0.1329,  0.2309, -0.0340, -0.2905], device='cuda:0')\n",
      "conv2.lin_l.weight tensor([[-3.2805e-01,  8.0359e-02,  1.8689e-02,  ...,  1.3608e-01,\n",
      "         -7.6340e-03,  3.4550e-04],\n",
      "        [ 4.6175e-01,  3.0508e-03,  4.7394e-01,  ..., -7.3169e-01,\n",
      "         -5.5104e-02, -4.2378e-02],\n",
      "        [-5.6642e-01,  1.4872e-01, -5.7868e-01,  ...,  4.8497e-02,\n",
      "         -2.4020e-02, -8.6134e-02],\n",
      "        [ 3.2483e-01, -6.1327e-02,  5.0530e-02,  ...,  3.6962e-01,\n",
      "         -1.4551e-01, -3.8234e-01],\n",
      "        [-1.9399e-02,  2.1337e-01, -8.2685e-02,  ...,  1.7646e-01,\n",
      "          2.3321e-01,  8.4691e-02]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}