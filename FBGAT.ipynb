{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "7d41162e4de29c5fd72b5adc7d8948e6c7ead7b24a5981c896f1e46711281ae4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import torch_geometric.nn as gnn\n",
    "import torch_geometric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.linalg\n",
    "from torch_geometric.nn import GATConv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/film/out1_node_feature_label.txt\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/film/out1_graph_edges.txt\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/film_split_0.6_0.2_0.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/film_split_0.6_0.2_1.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/film_split_0.6_0.2_2.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/film_split_0.6_0.2_3.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/film_split_0.6_0.2_4.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/film_split_0.6_0.2_5.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/film_split_0.6_0.2_6.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/film_split_0.6_0.2_7.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/film_split_0.6_0.2_8.npz\n",
      "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/film_split_0.6_0.2_9.npz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# from torch_geometric.datasets import Planetoid\n",
    "# name_data = 'Cora'\n",
    "# dataset = Planetoid(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WebKB\n",
    "# name_data = 'Wisconsin'\n",
    "# dataset = WebKB(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "# name_data = 'PubMed'\n",
    "# dataset = Planetoid(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "from torch_geometric.datasets import Actor\n",
    "dataset = Actor(root = '/tmp' + \"Actor\")\n",
    "\n",
    "# from torch_geometric.datasets import WebKB\n",
    "# name_data = 'Cornell'\n",
    "# dataset = WebKB(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WebKB\n",
    "# name_data = 'Texas'\n",
    "# dataset = WebKB(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WikipediaNetwork\n",
    "# name_data = 'Chameleon'\n",
    "# dataset = WikipediaNetwork(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WikipediaNetwork\n",
    "# name_data = 'Squirrel'\n",
    "# dataset = WikipediaNetwork(root= '/tmp/' + name_data, name = name_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30019/30019 [00:00<00:00, 52480.83it/s]\n",
      "100%|██████████| 7600/7600 [03:20<00:00, 37.81it/s]\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "\n",
    "edges = data.edge_index\n",
    "\n",
    "#dimension: num_nodes * num_features\n",
    "features = data.x\n",
    "\n",
    "num_nodes = features.shape[0]\n",
    "num_features = features.shape[1]\n",
    "#dimension: num_nodes * num_nodes\n",
    "adj = torch.zeros((num_nodes,num_nodes))\n",
    "degree = torch.zeros((num_nodes,num_nodes))\n",
    "for i in tqdm(range(edges.shape[1])):\n",
    "    first = edges[0][i]\n",
    "    second = edges[1][i]\n",
    "    adj[first][second] = 1\n",
    "    adj[second][first] = 1\n",
    "for i in tqdm(range(num_nodes)):\n",
    "    degree[i][i] = sum(adj[i][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sample(num_nodes):\n",
    "  sample_num = int(num_nodes*0.6)\n",
    "  sample_lst = np.random.choice(num_nodes,sample_num, replace = False)\n",
    "  train_mask = [False] * num_nodes\n",
    "  test_mask = [True] * num_nodes\n",
    "  for i in sample_lst:\n",
    "    train_mask[i] = True\n",
    "    test_mask[i] = False\n",
    "  train_mask = torch.tensor(train_mask)\n",
    "  test_mask = torch.tensor(test_mask)\n",
    "  return train_mask, test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_parameter(model):\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = degree.to(device)\n",
    "adj = adj.to(device)\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBLayer(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "      super().__init__()\n",
    "      self.low = nn.Linear(dim_in, dim_out, bias = False)\n",
    "      gain = nn.init.calculate_gain(\"relu\")\n",
    "      nn.init.xavier_normal_(self.low.weight, gain)\n",
    "      self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input, adj, degree, d_inv):\n",
    "      lap = degree - adj\n",
    "      Llp = torch.mm(torch.mm(d_inv, lap), d_inv)\n",
    "      Hl = torch.mm(Llp, self.activation(self.low(input)))\n",
    "      return Hl\n",
    "\n",
    "    def reset_parameter():\n",
    "      gain = nn.init.calculate_gain(\"relu\")\n",
    "      nn.init.xavier_normal_(self.low.weight, gain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, num_head, nhid):\n",
    "        super().__init__()\n",
    "        self.gc1 = GATConv(dataset.num_node_features, nhid, heads=num_head)\n",
    "        self.gc2 = GATConv(nhid*num_head, dataset.num_classes)\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.gc1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.gc2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBGAT(torch.nn.Module):\n",
    "    def __init__(self, num_head, nhid):\n",
    "      super().__init__()\n",
    "      self.fb1 = FBLayer(dataset.num_node_features, nhid*num_head)\n",
    "      self.fb2 = FBLayer(nhid*num_head ,dataset.num_classes)\n",
    "      self.conv1 = GATConv(dataset.num_node_features, nhid, heads = num_head)\n",
    "      self.conv2 = GATConv(nhid*num_head, dataset.num_classes)\n",
    "      self.aL_1 = torch.nn.Parameter(torch.rand(1))\n",
    "      self.aH_1 = torch.nn.Parameter(torch.rand(1))\n",
    "      self.aL_2 = torch.nn.Parameter(torch.rand(1))\n",
    "      self.aH_2 = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, data, adj, degree, d_inv):\n",
    "      input, edge_index = data.x, data.edge_index\n",
    "      x_1 = self.fb1(input, adj, degree, d_inv) #high pass\n",
    "      y_1 = self.conv1(input, edge_index) #low pass layer\n",
    "      z_1 = self.aL_1 * x_1 + self.aH_1 * y_1\n",
    "      z_1 = F.elu(z_1)\n",
    "      z_1 = F.dropout(z_1, training=self.training)\n",
    "      x_2 = self.fb2(z_1, adj, degree, d_inv)\n",
    "      y_2 = self.conv2(z_1, edge_index)\n",
    "      z_2 = self.aL_2 * x_2 + self.aH_2 * y_2\n",
    "\n",
    "      return F.log_softmax(z_2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]Number of Trial: 0\n",
      "100%|██████████| 100/100 [00:05<00:00, 16.74it/s]\n",
      "  4%|▍         | 4/100 [00:00<00:03, 29.84it/s]Number of Trial: 1\n",
      "100%|██████████| 100/100 [00:03<00:00, 26.82it/s]\n",
      "  4%|▍         | 4/100 [00:00<00:03, 30.30it/s]Number of Trial: 2\n",
      "100%|██████████| 100/100 [00:03<00:00, 26.92it/s]\n",
      "  4%|▍         | 4/100 [00:00<00:03, 29.84it/s]Number of Trial: 3\n",
      "100%|██████████| 100/100 [00:03<00:00, 26.90it/s]\n",
      "  4%|▍         | 4/100 [00:00<00:03, 30.30it/s]Number of Trial: 4\n",
      "100%|██████████| 100/100 [00:03<00:00, 26.88it/s]\n"
     ]
    }
   ],
   "source": [
    "acc_list_2 = []\n",
    "for i in range(5):\n",
    "    model_2 = GAT(48, 8).to(device)\n",
    "    optimizer_2 = torch.optim.Adam(model_2.parameters(), lr=0.05, weight_decay=5e-5)\n",
    "    model_2.train()\n",
    "    print(\"Number of Trial: \" + str(i))\n",
    "    reset_parameter(model_2)\n",
    "    train_mask, test_mask = data_sample(num_nodes)\n",
    "    for epoch in tqdm(range(100)):\n",
    "        optimizer_2.zero_grad()\n",
    "        out = model_2(data)\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask]) \n",
    "        loss.backward()\n",
    "        optimizer_2.step()\n",
    "    model_2.eval()\n",
    "    _, pred = model_2(data).max(dim=1)\n",
    "    correct = int(pred[test_mask].eq(data.y[test_mask]).sum().item())\n",
    "    acc = correct / int(test_mask.sum())\n",
    "    acc_list_2.append(acc)\n",
    "    del model_2,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.25861842105263155\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(acc_list_2))\n",
    "del acc_list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]Number of Trial: 0\n",
      "100%|██████████| 100/100 [03:09<00:00,  1.89s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]Number of Trial: 1\n",
      "100%|██████████| 100/100 [03:14<00:00,  1.94s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]Number of Trial: 2\n",
      "100%|██████████| 100/100 [03:08<00:00,  1.89s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]Number of Trial: 3\n",
      "100%|██████████| 100/100 [03:11<00:00,  1.91s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]Number of Trial: 4\n",
      "100%|██████████| 100/100 [03:09<00:00,  1.90s/it]\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "inter = scipy.linalg.fractional_matrix_power(degree.cpu(), (-1/2))\n",
    "d_inv = torch.from_numpy(inter).to(device)\n",
    "for i in range(5):\n",
    "    model = FBGAT(48, 8).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=5e-5)\n",
    "    model.train()\n",
    "    print(\"Number of Trial: \" + str(i))\n",
    "    reset_parameter(model)\n",
    "    train_mask, test_mask = data_sample(num_nodes)\n",
    "    for epoch in tqdm(range(100)):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data, adj, degree, d_inv)\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask]) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    _, pred = model(data, adj, degree, d_inv).max(dim=1)\n",
    "    correct = int(pred[test_mask].eq(data.y[test_mask]).sum() .item())\n",
    "    acc = correct / int(test_mask.sum())\n",
    "    acc_list.append(acc)\n",
    "    del model, correct\n",
    "del d_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FBGAT Accuracy: 0.3020\n"
     ]
    }
   ],
   "source": [
    "print('FBGAT Accuracy: {:.4f}'.format(np.mean(acc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1e3d987e5f43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}