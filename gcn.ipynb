{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0fc428ca26affa5af9dd5c051ba311245887c388f59b707cd674a8c125ddecc9a",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn as gnn\n",
    "import torch_geometric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.linalg\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "name_data = 'Cora'\n",
    "dataset = Planetoid(root= '/tmp/' + name_data, name = name_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import WebKB\n",
    "name_data = 'Wisconsin'\n",
    "dataset = WebKB(root= '/tmp/' + name_data, name = name_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "name_data = 'Cora'\n",
    "dataset = Planetoid(root= '/tmp/' + name_data, name = name_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0]\n",
    "\n",
    "edges = data.edge_index\n",
    "\n",
    "#dimension: num_nodes * num_features\n",
    "features = data.x\n",
    "\n",
    "num_nodes = features.shape[0]\n",
    "num_features = features.shape[1]\n",
    "#dimension: num_nodes * num_nodes\n",
    "adj = torch.zeros((num_nodes,num_nodes))\n",
    "degree = torch.zeros((num_nodes,num_nodes))\n",
    "for i in range(num_nodes):\n",
    "    first = edges[0][i]\n",
    "    second = edges[1][i]\n",
    "    adj[first][second] = 1\n",
    "    adj[second][first] = 1\n",
    "for i in range(num_nodes):\n",
    "    degree[i][i] = sum(adj[i][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = int(num_nodes*0.6)\n",
    "sample_lst = np.random.choice(num_nodes,sample_num, replace = False)\n",
    "train_mask = [False] * num_nodes\n",
    "test_mask = [True] * num_nodes\n",
    "for i in sample_lst:\n",
    "  train_mask[i] = True\n",
    "  test_mask[i] = False\n",
    "train_mask = torch.tensor(train_mask)\n",
    "test_mask = torch.tensor(test_mask)\n",
    "degree = degree.to(device)\n",
    "adj = adj.to(device)\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "      self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, input, edge):\n",
    "      x = input\n",
    "      edge_index = edge\n",
    "      x = self.conv1(x, edge_index)\n",
    "      x = F.relu(x)\n",
    "      x = F.dropout(x, training=self.training)\n",
    "      x = self.conv2(x, edge_index)\n",
    "\n",
    "      return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBLayer(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "      super().__init__()\n",
    "      self.low = nn.Linear(dim_in, dim_out, bias = False)\n",
    "      self.high = nn.Linear(dim_in, dim_out, bias = False)\n",
    "      self.aL = torch.nn.Parameter(torch.rand(1))\n",
    "      self.aH = torch.nn.Parameter(torch.rand(1))\n",
    "      gain = nn.init.calculate_gain(\"relu\")\n",
    "      nn.init.xavier_normal_(self.low.weight, gain)\n",
    "      nn.init.xavier_normal_(self.high.weight, gain)\n",
    "      self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input, adj, degree):\n",
    "      lap = degree - adj\n",
    "      inter = scipy.linalg.fractional_matrix_power(degree.cpu(), (-1/2))\n",
    "      d_inv = torch.from_numpy(inter).to(device)\n",
    "      Llp = torch.mm(torch.mm(d_inv, lap), d_inv)\n",
    "      Lhp = torch.eye(input.shape[0]).to(device) - Llp\n",
    "      Hl = torch.mm(Llp, self.activation(self.low(input)))\n",
    "      Hh = torch.mm(Lhp, self.activation(self.high(input)))\n",
    "      H = self.aL * Hl + self.aH * Hh\n",
    "      return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBGCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.fb1 = FBLayer(dataset.num_node_features,dataset.num_node_features)\n",
    "      self.fb2 = FBLayer(dataset.num_node_features,dataset.num_node_features)\n",
    "      self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "      self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data, adj, degree):\n",
    "      input, edge_index = data.x, data.edge_index\n",
    "      x = self.fb1(input, adj, degree)\n",
    "      x = self.fb2(x, adj, degree)\n",
    "      x = self.conv1(x, edge_index)\n",
    "      x = F.relu(x)\n",
    "      x = F.dropout(x, training=self.training)\n",
    "      x = self.conv2(x, edge_index)\n",
    "\n",
    "      return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FB(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "      super().__init__()\n",
    "      self.layer1 = FBLayer(dim_in, 128)\n",
    "      self.layer2 = FBLayer(128, 64)\n",
    "      self.layer3 = FBLayer(64, dim_out)\n",
    "    def forward(self, input, adjacency, degree):\n",
    "      ret = self.layer1(input, adjacency, degree)\n",
    "      ret = self.layer2(ret, adjacency, degree)\n",
    "      ret = self.layer3(ret, adjacency,degree)\n",
    "      return F.log_softmax(ret, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GCN only Accuracy: 0.8708\n"
     ]
    }
   ],
   "source": [
    "model1 = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.05, weight_decay=5e-5)\n",
    "total = 0\n",
    "test_num = 1\n",
    "for i in range(0,test_num):\n",
    "  model1.train()\n",
    "  for epoch in range(100):\n",
    "      optimizer.zero_grad()\n",
    "      out = model1(data.x, data.edge_index)\n",
    "      loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "  model1.eval()\n",
    "  _, pred = model1(data.x, data.edge_index).max(dim=1)\n",
    "  correct = int(pred[test_mask].eq(data.y[test_mask]).sum().item())\n",
    "  acc = correct / int(test_mask.sum())\n",
    "  total += acc\n",
    "total = total/test_num\n",
    "print('GCN only Accuracy: {:.4f}'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FBGCN Accuracy: 0.1365\n"
     ]
    }
   ],
   "source": [
    "model = FBGCN()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=5e-5)\n",
    "for i in range(0,1):\n",
    "  model.train()\n",
    "  for epoch in range(100):\n",
    "      optimizer.zero_grad()\n",
    "      out = model(data, adj, degree)\n",
    "      loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "model.eval()\n",
    "_, pred = model(data, adj, degree).max(dim=1)\n",
    "correct = int(pred[test_mask].eq(data.y[test_mask]).sum().item())\n",
    "acc = correct / int(test_mask.sum())\n",
    "print('FBGCN Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'FB' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-939b2ff325c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5e-5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0madj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdegree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FB' is not defined"
     ]
    }
   ],
   "source": [
    "model2 = FB(num_features, dataset.num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.05, weight_decay=5e-5)\n",
    "features = features.to(device)\n",
    "adj = adj.to(device)\n",
    "degree = degree.to(device)\n",
    "total = 0\n",
    "test_num = 1\n",
    "for i in range(0,test_num):\n",
    "  model2.train()\n",
    "  for epoch in range(100):\n",
    "      optimizer.zero_grad()\n",
    "      out = model2(features, adj, degree)\n",
    "      loss = F.nll_loss(out[train_mask], data.y[train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "  model2.eval()\n",
    "  _, pred = model2(features, adj, degree).max(dim=1)\n",
    "  correct = int(pred[test_mask].eq(data.y[test_mask]).sum().item())\n",
    "  acc = correct / int(test_mask.sum())\n",
    "  total += acc\n",
    "\n",
    "total = total/test_num\n",
    "print('FB only Accuracy: {:.4f}'.format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap = degree - adj\n",
    "print(torch.transpose(features,0, 1).shape)\n",
    "print(lap.shape)\n",
    "EGS_feature = torch.trace(torch.mm(torch.mm(torch.transpose(features,0, 1), Llp), features))\n",
    "EG_feature = torch.trace(torch.mm(torch.transpose(features,0, 1), features))\n",
    "S_feature = EGS_feature / EG_feature\n",
    "print(S_feature)\n",
    "lap_l = lap.long()\n",
    "label = data.y.long()\n",
    "EGS_label = torch.matmul(torch.matmul(label, lap_l), label)\n",
    "EG_label = torch.matmul(label, label)\n",
    "S_label = EGS_label / EG_label\n",
    "print(S_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model2.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model1.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model2.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "       layer.reset_parameters()"
   ]
  }
 ]
}