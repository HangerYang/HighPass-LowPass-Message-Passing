{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "fc428ca26affa5af9dd5c051ba311245887c388f59b707cd674a8c125ddecc9a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.linalg\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.datasets import Planetoid\n",
    "# name_data = 'Cora'\n",
    "# dataset = Planetoid(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import Actor\n",
    "# dataset = Actor(root= '/tmp/' + \"Actor\")\n",
    "\n",
    "# from torch_geometric.datasets import WebKB\n",
    "# name_data = 'Wisconsin'\n",
    "# dataset = WebKB(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "# name_data = 'CiteSeer'\n",
    "# dataset = Planetoid(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WebKB\n",
    "# name_data = 'Cornell'\n",
    "# dataset = WebKB(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WebKB\n",
    "# name_data = 'Texas'\n",
    "# dataset = WebKB(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "from torch_geometric.datasets import WikipediaNetwork\n",
    "name_data = 'Chameleon'\n",
    "dataset = WikipediaNetwork(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WikipediaNetwork\n",
    "# name_data = 'Squirrel'\n",
    "# dataset = WikipediaNetwork(root= '/tmp/' + name_data, name = name_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 36101/36101 [00:01<00:00, 20318.08it/s]\n",
      "100%|██████████| 2277/2277 [00:34<00:00, 66.61it/s]\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "\n",
    "edges = data.edge_index\n",
    "\n",
    "#dimension: num_nodes * num_features\n",
    "features = data.x\n",
    "\n",
    "num_nodes = features.shape[0]\n",
    "num_features = features.shape[1]\n",
    "#dimension: num_nodes * num_nodes\n",
    "adj = torch.eye((num_nodes))\n",
    "degree = torch.zeros((num_nodes, num_nodes))\n",
    "for i in tqdm(range(edges.shape[1])):\n",
    "    first = edges[0][i]\n",
    "    second = edges[1][i]\n",
    "    adj[first][second] = 1\n",
    "    adj[second][first] = 1\n",
    "for i in tqdm(range(num_nodes)):\n",
    "    degree[i][i] = sum(adj[i][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = int(num_nodes*0.6)\n",
    "sample_lst = np.random.choice(num_nodes,sample_num, replace = False)\n",
    "train_mask = [False] * num_nodes\n",
    "test_mask = [True] * num_nodes\n",
    "for i in sample_lst:\n",
    "  train_mask[i] = True\n",
    "  test_mask[i] = False\n",
    "train_mask = torch.tensor(train_mask)\n",
    "test_mask = torch.tensor(test_mask)\n",
    "degree = degree.to(device)\n",
    "adj = adj.to(device)\n",
    "data = data.to(device)\n",
    "features = features.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2277\n2325\n2325\n"
     ]
    }
   ],
   "source": [
    "print(num_nodes)\n",
    "print(num_features)\n",
    "print(dataset.num_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBLayer(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "      super().__init__()\n",
    "      self.high = nn.Linear(dim_in, dim_out, bias = False)\n",
    "      gain = nn.init.calculate_gain(\"relu\")\n",
    "      nn.init.xavier_normal_(self.high.weight, gain)\n",
    "      self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input, lap, d_inv):\n",
    "      Lhp = torch.mm(torch.mm(d_inv, lap), d_inv)\n",
    "      Hh = torch.mm(Lhp, self.activation(self.high(input)))\n",
    "      return Hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "      self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "      x, edge_index = data.x, data.edge_index\n",
    "      x = self.conv1(x, edge_index)\n",
    "      x = F.relu(x)\n",
    "      x = F.dropout(x, training=self.training)\n",
    "      x = self.conv2(x, edge_index)\n",
    "\n",
    "      return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBGCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.fb1 = FBLayer(dataset.num_node_features, 16)\n",
    "      self.fb2 = FBLayer(16 ,dataset.num_classes)\n",
    "      self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "      self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "      self.aL_1 = torch.nn.Parameter(torch.rand(1))\n",
    "      self.aH_1 = torch.nn.Parameter(torch.rand(1))\n",
    "      self.aL_2 = torch.nn.Parameter(torch.rand(1))\n",
    "      self.aH_2 = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, data, lap, d_inv):\n",
    "      input, edge_index = data.x, data.edge_index\n",
    "      x_1 = self.fb1(input, lap, d_inv) #high pass\n",
    "      y_1 = self.conv1(input, edge_index) #low pass layer\n",
    "      z_1 = self.aH_1 * x_1 + self.aL_1 * y_1\n",
    "      z_1 = F.relu(z_1)\n",
    "      z_1 = F.dropout(z_1, training=self.training)\n",
    "      x_2 = self.fb2(z_1, lap, d_inv)\n",
    "      y_2 = self.conv2(z_1, edge_index)\n",
    "      z_2 = self.aH_2 * x_2 + self.aL_2 * y_2\n",
    "\n",
    "      return F.log_softmax(z_2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_list_2 = []\n",
    "# lap = degree - adj\n",
    "# inter = scipy.linalg.fractional_matrix_power(degree.cpu(), (-1/2))\n",
    "# d_inv = torch.from_numpy(inter).to(device)\n",
    "# for i in tqdm(range(5)):\n",
    "#     model_2 = GCN().to(device)\n",
    "#     model_2.train()\n",
    "#     optimizer = torch.optim.Adam(model_2.parameters(), lr=0.05 ,weight_decay=5e-5)\n",
    "#     for epoch in range(100):\n",
    "#         optimizer.zero_grad()\n",
    "#         out = model_2(data)\n",
    "#         loss = F.nll_loss(out[train_mask], data.y[train_mask]) \n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     model_2.eval()\n",
    "#     _, pred = model_2(data).max(dim=1)\n",
    "#     correct = int(pred[test_mask].eq(data.y[test_mask]).sum().item())\n",
    "#     acc = correct / int(test_mask.sum())\n",
    "#     acc_list_2.append(acc)\n",
    "#     del model_2\n",
    "#     del correct\n",
    "#     torch.cuda.empty_cache()\n",
    "# del d_inv, inter, lap\n",
    "# print('FBGCN Accuracy: {:.4f}'.format(np.mean(acc_list_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 100/100 [00:15<00:00,  6.49it/s]\n",
      "FBGCN Accuracy: 0.4786\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "lap = degree - adj\n",
    "inter = scipy.linalg.fractional_matrix_power(degree.cpu(), (-1/2))\n",
    "d_inv = torch.from_numpy(inter).to(device)\n",
    "for i in range(1):\n",
    "    model = FBGCN().to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05 ,weight_decay=5e-5)\n",
    "    for epoch in tqdm(range(100)):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data, lap, d_inv)\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask]) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    _, pred = model(data, lap, d_inv).max(dim=1)\n",
    "    correct = int(pred[test_mask].eq(data.y[test_mask]).sum().item())\n",
    "    acc = correct / int(test_mask.sum())\n",
    "    acc_list.append(acc)\n",
    "    del correct\n",
    "    torch.cuda.empty_cache()\n",
    "del d_inv, inter, lap\n",
    "del model\n",
    "print('FBGCN Accuracy: {:.4f}'.format(np.mean(acc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1e3d987e5f43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.children():\n",
    "#    if hasattr(layer, 'reset_parameters'):\n",
    "#        layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}