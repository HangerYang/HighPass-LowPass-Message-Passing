{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "fc428ca26affa5af9dd5c051ba311245887c388f59b707cd674a8c125ddecc9a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.linalg\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.datasets import Planetoid\n",
    "# name_data = 'Cora'\n",
    "# dataset = Planetoid(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import Actor\n",
    "# dataset = Actor(root= '/tmp/' + \"Actor\")\n",
    "\n",
    "from torch_geometric.datasets import WebKB\n",
    "name_data = 'Wisconsin'\n",
    "dataset = WebKB(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "# name_data = 'CiteSeer'\n",
    "# dataset = Planetoid(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WebKB\n",
    "# name_data = 'Cornell'\n",
    "# dataset = WebKB(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WebKB\n",
    "# name_data = 'Texas'\n",
    "# dataset = WebKB(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WikipediaNetwork\n",
    "# name_data = 'Chameleon'\n",
    "# dataset = WikipediaNetwork(root= '/tmp/' + name_data, name = name_data)\n",
    "\n",
    "# from torch_geometric.datasets import WikipediaNetwork\n",
    "# name_data = 'Squirrel'\n",
    "# dataset = WikipediaNetwork(root= '/tmp/' + name_data, name = name_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 515/515 [00:00<00:00, 32272.07it/s]\n",
      "100%|██████████| 251/251 [00:00<00:00, 778.80it/s]\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "\n",
    "edges = data.edge_index\n",
    "\n",
    "#dimension: num_nodes * num_features\n",
    "features = data.x\n",
    "\n",
    "num_nodes = features.shape[0]\n",
    "num_features = features.shape[1]\n",
    "#dimension: num_nodes * num_nodes\n",
    "adj = torch.zeros((num_nodes,num_nodes))\n",
    "degree = torch.zeros((num_nodes,num_nodes))\n",
    "for i in tqdm(range(edges.shape[1])):\n",
    "    first = edges[0][i]\n",
    "    second = edges[1][i]\n",
    "    adj[first][second] = 1\n",
    "    adj[second][first] = 1\n",
    "for i in tqdm(range(num_nodes)):\n",
    "    degree[i][i] = sum(adj[i][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = int(num_nodes*0.6)\n",
    "sample_lst = np.random.choice(num_nodes,sample_num, replace = False)\n",
    "train_mask = [False] * num_nodes\n",
    "test_mask = [True] * num_nodes\n",
    "for i in sample_lst:\n",
    "  train_mask[i] = True\n",
    "  test_mask[i] = False\n",
    "train_mask = torch.tensor(train_mask)\n",
    "test_mask = torch.tensor(test_mask)\n",
    "degree = degree.to(device)\n",
    "adj = adj.to(device)\n",
    "data = data.to(device)\n",
    "features = features.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBLayer(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "      super().__init__()\n",
    "      self.low = nn.Linear(dim_in, dim_out, bias = False)\n",
    "      gain = nn.init.calculate_gain(\"relu\")\n",
    "      nn.init.xavier_normal_(self.low.weight, gain)\n",
    "      self.activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input, lap, d_inv):\n",
    "      Llp = torch.mm(torch.mm(d_inv, lap), d_inv)\n",
    "      Hl = torch.mm(Llp, self.activation(self.low(input)))\n",
    "      return Hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "      self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "      x, edge_index = data.x, data.edge_index\n",
    "      x = self.conv1(x, edge_index)\n",
    "      x = F.relu(x)\n",
    "      x = F.dropout(x, training=self.training)\n",
    "      x = self.conv2(x, edge_index)\n",
    "\n",
    "      return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FBGCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self.fb1 = FBLayer(dataset.num_node_features, 16)\n",
    "      self.fb2 = FBLayer(16 ,dataset.num_classes)\n",
    "      self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "      self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "      self.aL_1 = torch.nn.Parameter(torch.rand(1))\n",
    "      self.aH_1 = torch.nn.Parameter(torch.rand(1))\n",
    "      self.aL_2 = torch.nn.Parameter(torch.rand(1))\n",
    "      self.aH_2 = torch.nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, data, lap, d_inv):\n",
    "      input, edge_index = data.x, data.edge_index\n",
    "      x_1 = self.fb1(input, lap, d_inv) #high pass\n",
    "      y_1 = self.conv1(input, edge_index) #low pass layer\n",
    "      z_1 = self.aL_1 * x_1 + self.aH_1 * y_1\n",
    "      z_1 = F.relu(z_1)\n",
    "      z_1 = F.dropout(z_1, training=self.training)\n",
    "      x_2 = self.fb2(z_1, lap, d_inv)\n",
    "      y_2 = self.conv2(z_1, edge_index)\n",
    "      z_2 = self.aL_2 * x_2 + self.aH_2 * y_2\n",
    "\n",
    "      return F.log_softmax(z_2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:02<03:27,  2.10s/it]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:02<00:08,  9.99it/s]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:02<00:03, 22.37it/s]\u001b[A\n",
      " 48%|████▊     | 48/100 [00:02<00:01, 36.74it/s]\u001b[A\n",
      " 61%|██████    | 61/100 [00:02<00:00, 48.31it/s]\u001b[A\n",
      " 74%|███████▍  | 74/100 [00:02<00:00, 59.73it/s]\u001b[A\n",
      " 87%|████████▋ | 87/100 [00:02<00:00, 70.40it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.53it/s]\n",
      " 20%|██        | 1/5 [00:02<00:11,  2.94s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 11/100 [00:00<00:00, 101.94it/s]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:00<00:00, 104.97it/s]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:00<00:00, 107.09it/s]\u001b[A\n",
      " 45%|████▌     | 45/100 [00:00<00:00, 110.77it/s]\u001b[A\n",
      " 57%|█████▋    | 57/100 [00:00<00:00, 112.88it/s]\u001b[A\n",
      " 70%|███████   | 70/100 [00:00<00:00, 114.01it/s]\u001b[A\n",
      " 82%|████████▏ | 82/100 [00:00<00:00, 114.81it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 112.71it/s]\n",
      " 40%|████      | 2/5 [00:03<00:05,  1.74s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 11/100 [00:00<00:00, 102.12it/s]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:00<00:00, 98.75it/s] \u001b[A\n",
      " 32%|███▏      | 32/100 [00:00<00:00, 97.38it/s]\u001b[A\n",
      " 42%|████▏     | 42/100 [00:00<00:00, 93.18it/s]\u001b[A\n",
      " 52%|█████▏    | 52/100 [00:00<00:00, 89.63it/s]\u001b[A\n",
      " 61%|██████    | 61/100 [00:00<00:00, 81.98it/s]\u001b[A\n",
      " 73%|███████▎  | 73/100 [00:00<00:00, 91.23it/s]\u001b[A\n",
      " 85%|████████▌ | 85/100 [00:00<00:00, 97.39it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:01<00:00, 96.81it/s]\n",
      " 60%|██████    | 3/5 [00:04<00:02,  1.42s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 11/100 [00:00<00:00, 101.93it/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:00<00:00, 109.76it/s]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:00<00:00, 114.54it/s]\u001b[A\n",
      " 49%|████▉     | 49/100 [00:00<00:00, 115.32it/s]\u001b[A\n",
      " 61%|██████    | 61/100 [00:00<00:00, 114.55it/s]\u001b[A\n",
      " 73%|███████▎  | 73/100 [00:00<00:00, 114.70it/s]\u001b[A\n",
      " 86%|████████▌ | 86/100 [00:00<00:00, 118.59it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 117.51it/s]\n",
      " 80%|████████  | 4/5 [00:05<00:01,  1.21s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:00<00:00, 118.82it/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:00<00:00, 115.57it/s]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:00<00:00, 118.88it/s]\u001b[A\n",
      " 49%|████▉     | 49/100 [00:00<00:00, 114.44it/s]\u001b[A\n",
      " 61%|██████    | 61/100 [00:00<00:00, 108.17it/s]\u001b[A\n",
      " 72%|███████▏  | 72/100 [00:00<00:00, 106.40it/s]\u001b[A\n",
      " 84%|████████▍ | 84/100 [00:00<00:00, 108.32it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 110.09it/s]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.34s/it]FBGCN Accuracy: 0.4257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_list_2 = []\n",
    "lap = degree - adj\n",
    "inter = scipy.linalg.fractional_matrix_power(degree.cpu(), (-1/2))\n",
    "d_inv = torch.from_numpy(inter).to(device)\n",
    "for i in tqdm(range(5)):\n",
    "    model_2 = GCN().to(device)\n",
    "    model_2.train()\n",
    "    optimizer = torch.optim.Adam(model_2.parameters(), lr=0.05 ,weight_decay=5e-5)\n",
    "    for epoch in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        out = model_2(data)\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask]) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model_2.eval()\n",
    "    _, pred = model_2(data).max(dim=1)\n",
    "    correct = int(pred[test_mask].eq(data.y[test_mask]).sum().item())\n",
    "    acc = correct / int(test_mask.sum())\n",
    "    acc_list_2.append(acc)\n",
    "    del model_2\n",
    "    del correct\n",
    "    torch.cuda.empty_cache()\n",
    "del d_inv, inter, lap\n",
    "print('FBGCN Accuracy: {:.4f}'.format(np.mean(acc_list_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 5/100 [00:00<00:02, 45.99it/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:00<00:01, 47.27it/s]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:00<00:01, 46.88it/s]\u001b[A\n",
      " 21%|██        | 21/100 [00:00<00:01, 48.94it/s]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:00<00:01, 51.35it/s]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:00<00:01, 53.48it/s]\u001b[A\n",
      " 41%|████      | 41/100 [00:00<00:00, 60.18it/s]\u001b[A\n",
      " 48%|████▊     | 48/100 [00:00<00:00, 62.78it/s]\u001b[A\n",
      " 55%|█████▌    | 55/100 [00:00<00:00, 63.44it/s]\u001b[A\n",
      " 63%|██████▎   | 63/100 [00:01<00:00, 67.61it/s]\u001b[A\n",
      " 70%|███████   | 70/100 [00:01<00:00, 67.78it/s]\u001b[A\n",
      " 80%|████████  | 80/100 [00:01<00:00, 72.62it/s]\u001b[A\n",
      " 88%|████████▊ | 88/100 [00:01<00:00, 72.71it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:01<00:00, 63.73it/s]\n",
      " 20%|██        | 1/5 [00:01<00:06,  1.60s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|▉         | 9/100 [00:00<00:01, 83.11it/s]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:00<00:01, 81.99it/s]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:00<00:00, 83.41it/s]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:00<00:00, 84.72it/s]\u001b[A\n",
      " 47%|████▋     | 47/100 [00:00<00:00, 86.47it/s]\u001b[A\n",
      " 57%|█████▋    | 57/100 [00:00<00:00, 88.61it/s]\u001b[A\n",
      " 68%|██████▊   | 68/100 [00:00<00:00, 92.77it/s]\u001b[A\n",
      " 78%|███████▊  | 78/100 [00:00<00:00, 92.50it/s]\u001b[A\n",
      " 88%|████████▊ | 88/100 [00:01<00:00, 88.02it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:01<00:00, 85.80it/s]\n",
      " 40%|████      | 2/5 [00:02<00:04,  1.36s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|▋         | 7/100 [00:00<00:01, 64.19it/s]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:00<00:01, 78.92it/s]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:00<00:00, 78.73it/s]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:00<00:00, 82.42it/s]\u001b[A\n",
      " 43%|████▎     | 43/100 [00:00<00:00, 77.27it/s]\u001b[A\n",
      " 51%|█████     | 51/100 [00:00<00:00, 76.22it/s]\u001b[A\n",
      " 61%|██████    | 61/100 [00:00<00:00, 80.23it/s]\u001b[A\n",
      " 71%|███████   | 71/100 [00:00<00:00, 84.82it/s]\u001b[A\n",
      " 81%|████████  | 81/100 [00:00<00:00, 88.99it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:01<00:00, 84.95it/s]\n",
      " 60%|██████    | 3/5 [00:03<00:02,  1.28s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|▉         | 9/100 [00:00<00:01, 87.23it/s]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:00<00:00, 89.61it/s]\u001b[A\n",
      " 30%|███       | 30/100 [00:00<00:00, 96.87it/s]\u001b[A\n",
      " 41%|████      | 41/100 [00:00<00:00, 98.60it/s]\u001b[A\n",
      " 52%|█████▏    | 52/100 [00:00<00:00, 100.74it/s]\u001b[A\n",
      " 63%|██████▎   | 63/100 [00:00<00:00, 101.55it/s]\u001b[A\n",
      " 74%|███████▍  | 74/100 [00:00<00:00, 101.59it/s]\u001b[A\n",
      " 85%|████████▌ | 85/100 [00:00<00:00, 103.52it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 100.46it/s]\n",
      " 80%|████████  | 4/5 [00:04<00:01,  1.17s/it]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█         | 11/100 [00:00<00:00, 106.20it/s]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:00<00:00, 94.15it/s] \u001b[A\n",
      " 33%|███▎      | 33/100 [00:00<00:00, 98.20it/s]\u001b[A\n",
      " 44%|████▍     | 44/100 [00:00<00:00, 99.66it/s]\u001b[A\n",
      " 55%|█████▌    | 55/100 [00:00<00:00, 100.91it/s]\u001b[A\n",
      " 66%|██████▌   | 66/100 [00:00<00:00, 102.08it/s]\u001b[A\n",
      " 77%|███████▋  | 77/100 [00:00<00:00, 100.20it/s]\u001b[A\n",
      " 88%|████████▊ | 88/100 [00:00<00:00, 99.29it/s] \u001b[A\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.84it/s]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.20s/it]FBGCN Accuracy: 0.7267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "lap = degree - adj\n",
    "inter = scipy.linalg.fractional_matrix_power(degree.cpu(), (-1/2))\n",
    "d_inv = torch.from_numpy(inter).to(device)\n",
    "for i in tqdm(range(5)):\n",
    "    model = FBGCN().to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.05 ,weight_decay=5e-5)\n",
    "    for epoch in tqdm(range(100)):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data, lap, d_inv)\n",
    "        loss = F.nll_loss(out[train_mask], data.y[train_mask]) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    _, pred = model(data, lap, d_inv).max(dim=1)\n",
    "    correct = int(pred[test_mask].eq(data.y[test_mask]).sum().item())\n",
    "    acc = correct / int(test_mask.sum())\n",
    "    acc_list.append(acc)\n",
    "    del model\n",
    "    del correct\n",
    "    torch.cuda.empty_cache()\n",
    "del d_inv, inter, lap\n",
    "print('FBGCN Accuracy: {:.4f}'.format(np.mean(acc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.children():\n",
    "#    if hasattr(layer, 'reset_parameters'):\n",
    "#        layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}